---
layout: about
title: about
permalink: /

profile:
  align: center
  image: al-folio-preview.png
  address: >
    <p>TODO add picture and caption</p>
---

## Preface

TODO

## Background

**Content moderation** is the act of vetting user-generated content (UGC) that is regarded as irrelevant, obscene, illegal,
or otherwise as inappropriate for a given Internet service. In most cases, there is a central body that sets guidelines
for Although major social media sites like Facebook and Twitter have brought content moderation into the mainstream,
there are several other types of services that enforce guidelines on UGC: Internet forums, blogs, and news sites also
moderate content in increasingly unique ways. In short, content moderation happens in more places than you may expect.

At the same time, content moderation is fraught with controversy. With opaque and ever-changing guidelines, and relatively
little standardization across services, users can be easily confused about what types of posts are actually allowed on a given
service. A clear example of this is moderation of hate speech. In 2017, the New York Times [published a quiz](https://www.nytimeas.com/interactive/2017/10/13/technology/facebook-hate-speech-quiz.html)
that tested readers’ ability to “correctly” label content as meeting Facebook’s criteria for hate speech. The results are startling. In one case,
the given statement did not meet the criteria for hate speech, but in a follow-up question 92% of respondents said that they
did consider the statement to be hateful. This dissonance between what users think is allowed or not and what Facebook actually
permits is not only shocking, but dangerous: bad actors [can take advantage](https://www.propublica.org/article/facebook-enforcement-hate-speech-rules-mistakes) of inconsistencies to post harmful content.

To many, the content moderation problem seems easy: just have humans evaluate each piece of potentially harmful content objectively.
However, this approach runs into two main problems. First, the massive scale of companies like Facebook or Twitter means that there
are millions of controversial posts to comb through. The amount of human moderators required to perform fully-manual checking would
be too large for any one organization. In addition, there is a human cost to content moderation. There have been [countless](https://www.newyorker.com/news/q-and-a/the-underworld-of-online-content-moderation) [articles](https://www.theverge.com/2019/2/27/18243359/content-moderation-mental-health-ptsd-psychology-science-facebook)
on the psychological toll that content moderation takes on moderators. In an ideal world, automated tools would filter out as much
harmful content as possible, thereby minimizing the burden on moderators. There is a tension between manual and automated content
moderation, and it doesn’t seem like any platform has found the right balance.

But given its impact on society, the mechanics of content moderation must be constantly discussed. And given how many future computer
scientists will work on services that allow for UGC, it is imperative that ethics courses cover content moderation.

## The Project

[Fancy title] is a project designed to have students critically think about the ethics of content moderation. It is a programming-based
ethics assignment, and is designed to be completed individually. In addition, we provide questions designed to be discussed in groups or
through short papers after students complete the programming assignment. We _highly_ recommend that instructors integrate these non-technical
components into the completion of this project.

### Learning Objectives:

The learning objectives for this project are:

- Learn different ways in which content moderation can be performed and
- Compare and contrast the efficacy of each approach, from a technical, and ethical perspective.
- Consider the challenges that modern platforms face when performing content moderation.
- Understand the impact that content moderation (or lack thereof) has on users.

### Description:

TODO

This is an equation: $$f(x) = \int_{-\infty}^\infty \hat f(\xi)\,e^{2 \pi i \xi x} \,d\xi$$.

### Questions:

Some example questions that could follow the programming component are:

- In many cases, content could fall into the valid and invalid category. For example, a post about Colin Kapernick could also talk about kneeling for the national anthem. How should cases where there is no “clear” answer be handled?
- How do you balance human review in content moderation? How, if at all, does human review differ if you are a big company or a small one?
- Is there an “optimal” way to moderate content? Are there any best practices that any company maintaining UGC could apply?
- To what degree should speech be moderated? Should there be legal protections for speech on these platforms?

## FAQ

- **Why did you not use real Facebook/Twitter data?**
  - As we were constructing this assignment, we had to consider what was most appropriate for our audience. At a university, and especially at a large one like UIUC, students come from all walks of life. A significant portion of the content on Facebook -- and particularly the types of posts we’d need to include in our dataset -- would likely be extremely graphic, offensive, or both. We concluded that in order to provide all students with an optimal and safe learning experience, we should aim for our dataset and assignment to be neutral, while still being as illustrative as possible. We hope that we achieve this balance, but if you feel there is a different way we could set up the assignment, please let us know!

## Related Work

TODO

## Acknowledgements

TODO
